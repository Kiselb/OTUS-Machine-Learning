{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Базовая статья](https://learnopencv.com/multi-label-image-classification-with-pytorch-image-tagging/)\n",
    "\n",
    "[Базовый код](https://github.com/spmallick/learnopencv/blob/master/PyTorch-Multi-Label-Image-Classification-Image-Tagging/Pipeline.ipynb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torchvision import models\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from torch import nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_dir = 'D:/EDUCATION/DATA/OTUS_ML_P/train_images'\n",
    "data_test_dir = 'D:/EDUCATION/DATA/OTUS_ML_P/test_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Fish', 'Flower', 'Gravel', 'Sugar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_target(labels, classes=classes):\n",
    "    target = torch.zeros(len(classes))\n",
    "    for label in labels:\n",
    "        index = classes.index(label)\n",
    "        target[index] = 1\n",
    "    return target\n",
    "\n",
    "def decode_target(target, classes=classes, threshold=0.5):\n",
    "    result = []\n",
    "    for index, value in enumerate(target):\n",
    "        if value > threshold:\n",
    "            result.append(classes[index])\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(path):\n",
    "    result = []\n",
    "    for _, _, file_names in os.walk(path):  \n",
    "        for file_name in file_names:\n",
    "                result.append(file_name)\n",
    "    return result\n",
    "\n",
    "def get_labels(file_path):\n",
    "    labels = {}\n",
    "    \n",
    "    data = pd.read_csv(file_path)\n",
    "    data['File_Name'] = data['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "    data['Label'] = data['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "\n",
    "    data = data[data['EncodedPixels'].notna()]\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        if row['File_Name'] not in labels:\n",
    "            labels[row['File_Name']] = []\n",
    "        labels[row['File_Name']].append(row['Label'])\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagesDataset(Dataset):\n",
    "    def __init__(self, train_images_path='D:/EDUCATION/DATA/OTUS_ML_P/TRAIN_IMAGES', train_labels_file_path='D:/EDUCATION/DATA/OTUS_ML_P/TRAIN.CSV'):\n",
    "        self.train_images_path = train_images_path\n",
    "        self.train_labels_file_path = train_labels_file_path\n",
    "\n",
    "        self.images = get_file_names(train_images_path)\n",
    "        self.labels = get_labels(train_labels_file_path)\n",
    "      \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)       \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        transform = T.Compose([T.ToTensor()])\n",
    "\n",
    "        image_file_name = self.images[index]\n",
    "        image = transform(Image.open(os.path.join(self.train_images_path, image_file_name)))\n",
    "        \n",
    "        return image, encode_target(self.labels[image_file_name])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.9098, 0.8902, 0.8588],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.9176, 0.8784, 0.8314],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.8314, 0.7569, 0.6902],\n",
       "          ...,\n",
       "          [0.0588, 0.0588, 0.0588,  ..., 0.3922, 0.4863, 0.5843],\n",
       "          [0.0549, 0.0549, 0.0588,  ..., 0.4196, 0.5216, 0.5961],\n",
       "          [0.0549, 0.0549, 0.0549,  ..., 0.4471, 0.5569, 0.5922]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.9098, 0.8902, 0.8588],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.9176, 0.8784, 0.8314],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.8314, 0.7569, 0.6902],\n",
       "          ...,\n",
       "          [0.1059, 0.1059, 0.1059,  ..., 0.3961, 0.4902, 0.5882],\n",
       "          [0.1020, 0.1020, 0.1059,  ..., 0.4235, 0.5255, 0.6000],\n",
       "          [0.1020, 0.1020, 0.1020,  ..., 0.4510, 0.5608, 0.5961]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.9020, 0.8824, 0.8510],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.9098, 0.8706, 0.8235],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.8235, 0.7490, 0.6824],\n",
       "          ...,\n",
       "          [0.2078, 0.2078, 0.2078,  ..., 0.4039, 0.4980, 0.5961],\n",
       "          [0.2039, 0.2039, 0.2078,  ..., 0.4314, 0.5333, 0.6078],\n",
       "          [0.2039, 0.2039, 0.2039,  ..., 0.4588, 0.5686, 0.6039]]]),\n",
       " tensor([1., 1., 0., 0.]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ImagesDataset()\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4715, 831)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = len(data) - int(0.15 * len(data))\n",
    "val_size = len(data) - train_size\n",
    "train_size, val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4715, 831)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds, val_ds = random_split(data, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnext50(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        resnet = models.resnext50_32x4d(pretrained=True)\n",
    "        resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=resnet.fc.in_features, out_features=len(classes))\n",
    "        )\n",
    "        self.base_model = resnet\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigm(self.base_model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(pred, target, threshold=0.5):\n",
    "    pred = np.array(pred > threshold, dtype=float)\n",
    "    return {'micro/precision': precision_score(y_true=target, y_pred=pred, average='micro'),\n",
    "            'micro/recall': recall_score(y_true=target, y_pred=pred, average='micro'),\n",
    "            'micro/f1': f1_score(y_true=target, y_pred=pred, average='micro'),\n",
    "            'macro/precision': precision_score(y_true=target, y_pred=pred, average='macro'),\n",
    "            'macro/recall': recall_score(y_true=target, y_pred=pred, average='macro'),\n",
    "            'macro/f1': f1_score(y_true=target, y_pred=pred, average='macro'),\n",
    "            'samples/precision': precision_score(y_true=target, y_pred=pred, average='samples'),\n",
    "            'samples/recall': recall_score(y_true=target, y_pred=pred, average='samples'),\n",
    "            'samples/f1': f1_score(y_true=target, y_pred=pred, average='samples'),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4 \n",
    "test_freq = 200 # Test model frequency (iterations)\n",
    "max_epoch_number = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MVKiselev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\MVKiselev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = Resnext50(len(classes))\n",
    "model.train()\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MVKiselev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "c:\\Users\\MVKiselev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\MVKiselev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\MVKiselev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "c:\\Users\\MVKiselev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "iteration = 0\n",
    "while True:\n",
    "    batch_losses = []\n",
    "    for imgs, targets in train_loader:\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        model_result = model(imgs)\n",
    "        loss = criterion(model_result, targets.type(torch.float))\n",
    "\n",
    "        batch_loss_value = loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_losses.append(batch_loss_value)\n",
    "        with torch.no_grad():\n",
    "            result = calculate_metrics(model_result.cpu().numpy(), targets.cpu().numpy())\n",
    "\n",
    "        if iteration % test_freq == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                model_result = []\n",
    "                targets = []\n",
    "                for imgs, batch_targets in val_loader:\n",
    "                    imgs = imgs.to(device)\n",
    "                    model_batch_result = model(imgs)\n",
    "                    model_result.extend(model_batch_result.cpu().numpy())\n",
    "                    targets.extend(batch_targets.cpu().numpy())\n",
    "\n",
    "            result = calculate_metrics(np.array(model_result), np.array(targets))\n",
    "            print(\"epoch:{:2d} iter:{:3d} test: \"\n",
    "                  \"micro f1: {:.3f} \"\n",
    "                  \"macro f1: {:.3f} \"\n",
    "                  \"samples f1: {:.3f}\".format(epoch, iteration,\n",
    "                                              result['micro/f1'],\n",
    "                                              result['macro/f1'],\n",
    "                                              result['samples/f1']))\n",
    "\n",
    "            model.train()\n",
    "        iteration += 1\n",
    "\n",
    "    loss_value = np.mean(batch_losses)\n",
    "    print(\"epoch:{:2d} iter:{:3d} train: loss:{:.3f}\".format(epoch, iteration, loss_value))\n",
    "    epoch += 1\n",
    "    if max_epoch_number < epoch:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
